{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting emergency department visits anchored on clinic dates\n",
    "---\n",
    "## Background\n",
    "Before, we built a model to predict emergency department (ED) visits anchored on treatment dates.\n",
    "\n",
    "The problem with that is the primary physicians do not interact with their patients during their treatment sessions. They only meet during their clinic visits. That is the best time for the model to nudge the physician for an intervention. Thus, we now want to build a model to predict patient's risk of ED visits prior to clinic date instead of prior to treatment session.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd ../../\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from ml_common.summary import get_label_distribution\n",
    "from ml_common.util import load_pickle, save_pickle\n",
    "\n",
    "from preduce.acu.eval import evaluate_valid, evaluate_test, predict\n",
    "from preduce.acu.pipeline import PrepACUData\n",
    "from preduce.acu.train import train_models, tune_params\n",
    "from preduce.summarize import feature_summary\n",
    "from preduce.util import compute_threshold\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(levelname)s:%(message)s', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/processed/clinic_centered_feature_dataset.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = PrepACUData()\n",
    "df = prep.preprocess(df)\n",
    "X, Y, metainfo = prep.prepare(df, n_folds=5) # n_folds=3\n",
    "df = df.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask = metainfo['split'] == 'Train', metainfo['split'] == 'Test'\n",
    "X_train, X_test = X[train_mask], X[test_mask]\n",
    "Y_train, Y_test = Y[train_mask], Y[test_mask]\n",
    "metainfo_train, metainfo_test = metainfo[train_mask], metainfo[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data prep for silent deployment\n",
    "# So we transform new incoming data using the original data preparer\n",
    "save_pickle(prep, './result', 'prep_ED_visit_clinic_anchored')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pd.DataFrame({\n",
    "    'Number of sessions': metainfo.groupby('split').apply(len, include_groups=False), \n",
    "    'Number of patients': metainfo.groupby('split')['mrn'].nunique()}\n",
    ").T\n",
    "count['Total'] = count.sum(axis=1)\n",
    "print(f'\\n{count.to_string()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trts_prior = df['treatment_date'].isnull()\n",
    "pd.concat([\n",
    "    get_label_distribution(Y[no_trts_prior], metainfo[no_trts_prior], with_respect_to='sessions'),\n",
    "    get_label_distribution(Y[~no_trts_prior], metainfo[~no_trts_prior], with_respect_to='sessions'),\n",
    "    get_label_distribution(Y, metainfo, with_respect_to='sessions')\n",
    "], keys=['First Visit', 'Subsequent Visit', 'All'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    get_label_distribution(Y[no_trts_prior], metainfo[no_trts_prior], with_respect_to='patients'),\n",
    "    get_label_distribution(Y[~no_trts_prior], metainfo[~no_trts_prior], with_respect_to='patients'),\n",
    "    get_label_distribution(Y, metainfo, with_respect_to='patients')\n",
    "], keys=['First Visit', 'Subsequent Visit', 'All'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Characteristics\n",
    "x = prep.ohe.encode(df.loc[X_train.index].copy(), verbose=False) # get original (non-normalized, non-imputed) data one-hot encoded\n",
    "x = x[[col for col in x.columns if not (col in metainfo.columns or col.startswith('target'))]]\n",
    "feature_summary(x, save_path='result/tables/feature_summary_ED_clinic_anchored.csv').sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM does not like non alphanumeric characters (except for _)\n",
    "for char in ['(', ')', '+', '-', '/', ',']: \n",
    "    X_train.columns = X_train.columns.str.replace(char, '_')\n",
    "    X_test.columns = X_test.columns.str.replace(char, '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Hyperparameter tuning\n",
    "# TODO: try greater kappa for greater exploration\n",
    "algs = ['LASSO', 'RF', 'Ridge', 'XGB', 'LGBM']\n",
    "best_params = {}\n",
    "for alg in algs:\n",
    "    best_params[alg] = tune_params(alg, X_train, Y_train['ED_visit'], metainfo_train)\n",
    "save_pickle(best_params, './models', 'best_params_clinic_anchored')\n",
    "save_pickle(best_params, './models', f'best_params_clinic_anchored-{datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = load_pickle('./models', 'best_params_clinic_anchored')\n",
    "models = train_models(X_train, Y_train, metainfo_train, best_params) # NOTE: Number of CV folds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Select final model based on the average performance across the validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_valid(models, X_train, Y_train, metainfo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([evaluate_test(model, X_test, Y_test) for alg, model in models.items()], keys=models.keys()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models['XGB']\n",
    "mask = metainfo_test['treatment_date'].isnull()\n",
    "pd.concat([\n",
    "    evaluate_test(model, X_test[mask], Y_test[mask]),\n",
    "    evaluate_test(model, X_test[~mask], Y_test[~mask])\n",
    "], keys=['First Visit', 'Subsequent Visits']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute threshold that achieves 10% and 20% alarm rate\n",
    "pred = predict(model['ED_visit'], X_test)\n",
    "res = [compute_threshold(pred, desired_alarm_rate) for desired_alarm_rate in [0.1, 0.2]]\n",
    "pd.DataFrame(res, columns=['Prediction Threshold', 'Alarm Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(model['ED_visit'], './models', 'XGB_ED_visit_clinic_anchored')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autogluon Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from preduce.ag.eval import evaluate\n",
    "from preduce.ag.train import train_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_models(X_train, Y_train, metainfo_train, presets='medium_quality', eval_metric='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly check the validation scores\n",
    "models = {'ED_visit': TabularPredictor.load('./AutogluonModels/20250203_184425-ED_visit-medium-roc_auc', verbosity=0)}\n",
    "print(models['ED_visit'].leaderboard().head(n=5)[['model', 'score_val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, model in models.items(): \n",
    "    print(f'Best model for {target}: {model.model_best}')\n",
    "evaluate(models, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the predictor without all the extra files\n",
    "models['ED_visit'].clone_for_deployment('./AutogluonModels/WE_ED_visit_clinic_anchored')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim2reduce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
